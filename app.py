"""
Azure AI Search ç”»åƒæ¤œç´¢ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª
Streamlitã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ‡ãƒ¢
"""

import os
import base64
from datetime import datetime, timedelta
import traceback
import time
from urllib.parse import urlparse, unquote

import streamlit as st
import certifi
import httpx
from dotenv import load_dotenv
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from azure.core.credentials import AzureKeyCredential
from azure.storage.blob import generate_blob_sas, BlobSasPermissions
from PIL import Image
import io

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# Azure AI Searchè¨­å®š
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")

# Azure OpenAIè¨­å®š
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_CHAT_DEPLOYMENT_MINI = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_MINI", "gpt-5-mini")
AZURE_OPENAI_CHAT_DEPLOYMENT_NANO = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT_NANO", "gpt-5-nano")
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_SMALL = os.getenv(
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_SMALL", "text-embedding-3-small"
)
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_LARGE = os.getenv(
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_LARGE", "text-embedding-3-large"
)

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ‡ã‚Šæ›¿ãˆè¨­å®š
SEARCH_INDEX_NANO = os.getenv("SEARCH_INDEX_NANO", "geek-location-image-search-nano-index")
SEARCH_INDEX_MINI_SMALL = os.getenv("SEARCH_INDEX_MINI_SMALL", "geek-location-image-search-test-index")
SEARCH_INDEX_MINI_LARGE = os.getenv("SEARCH_INDEX_MINI_LARGE", "geek-location-image-search-large-mini-index")
SEARCH_INDEX_NANO_LARGE = os.getenv("SEARCH_INDEX_NANO_LARGE", "geek-location-image-search-large-nano-index")

# æ–™é‡‘ï¼ˆå††ï¼‰
PRICE_GPT5_NANO_INPUT_PER_1M = 7.68
PRICE_GPT5_NANO_OUTPUT_PER_1M = 61.4
PRICE_GPT5_MINI_INPUT_PER_1M = 38.38
PRICE_GPT5_MINI_OUTPUT_PER_1M = 306.99
PRICE_EMBEDDING_SMALL_PER_1K = 0.003838
PRICE_EMBEDDING_LARGE_PER_1K = 0.024252


def get_patterns() -> list[dict]:
    return [
        {
            "id": "mini_large",
            "label": "gpt-5-mini + emb-large",
            "chat": AZURE_OPENAI_CHAT_DEPLOYMENT_MINI,
            "embed": AZURE_OPENAI_EMBEDDING_DEPLOYMENT_LARGE,
            "index": SEARCH_INDEX_MINI_LARGE
        },
        {
            "id": "mini_small",
            "label": "gpt-5-mini + emb-small",
            "chat": AZURE_OPENAI_CHAT_DEPLOYMENT_MINI,
            "embed": AZURE_OPENAI_EMBEDDING_DEPLOYMENT_SMALL,
            "index": SEARCH_INDEX_MINI_SMALL
        },
        {
            "id": "nano_large",
            "label": "gpt-5-nano + emb-large",
            "chat": AZURE_OPENAI_CHAT_DEPLOYMENT_NANO,
            "embed": AZURE_OPENAI_EMBEDDING_DEPLOYMENT_LARGE,
            "index": SEARCH_INDEX_NANO_LARGE
        },
        {
            "id": "nano_small",
            "label": "gpt-5-nano + emb-small",
            "chat": AZURE_OPENAI_CHAT_DEPLOYMENT_NANO,
            "embed": AZURE_OPENAI_EMBEDDING_DEPLOYMENT_SMALL,
            "index": SEARCH_INDEX_NANO
        }
    ]

# Azure Blob Storageè¨­å®š
AZURE_STORAGE_ACCOUNT_NAME = os.getenv("AZURE_STORAGE_ACCOUNT_NAME")
AZURE_STORAGE_ACCOUNT_KEY = os.getenv("AZURE_STORAGE_ACCOUNT_KEY")


def init_openai_client() -> AzureOpenAI:
    """Azure OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
    http_client = httpx.Client(verify=certifi.where(), timeout=60.0)
    return AzureOpenAI(
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_API_KEY,
        api_version="2025-03-01-preview",
        http_client=http_client,
        timeout=60.0  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ60ç§’
    )


def test_connection(client: AzureOpenAI, chat_deployment: str) -> tuple[bool, str]:
    """Azure OpenAIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    try:
        client.chat.completions.create(
            model=chat_deployment,
            messages=[{"role": "user", "content": "Hello"}],
            max_completion_tokens=5
        )
        return True, "æ¥ç¶šæˆåŠŸ"
    except Exception as e:
        cause = repr(getattr(e, "__cause__", None))
        detail = traceback.format_exc()
        return False, f"{type(e).__name__}: {e}\nCAUSE={cause}\n{detail}"


def init_search_client(index_name: str) -> SearchClient:
    """Azure AI Searchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
    return SearchClient(
        endpoint=AZURE_SEARCH_ENDPOINT,
        index_name=index_name,
        credential=AzureKeyCredential(AZURE_SEARCH_API_KEY)
    )


def encode_image_to_base64(image_bytes: bytes) -> str:
    """ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
    return base64.b64encode(image_bytes).decode("utf-8")


def render_result_image(image_bytes: bytes, content_type: str, height_px: int = 220) -> None:
    data_url = f"data:{content_type};base64,{encode_image_to_base64(image_bytes)}"
    st.markdown(
        f"""
        <div class="result-card">
          <img src="{data_url}" class="result-image" style="height:{height_px}px;" />
        </div>
        """,
        unsafe_allow_html=True
    )


def _usage_get(usage, key: str) -> int:
    if usage is None:
        return 0
    if isinstance(usage, dict):
        return int(usage.get(key) or 0)
    return int(getattr(usage, key, 0) or 0)


def _extract_chat_usage(response) -> dict:
    usage = getattr(response, "usage", None)
    prompt = _usage_get(usage, "prompt_tokens")
    completion = _usage_get(usage, "completion_tokens")
    total = _usage_get(usage, "total_tokens") or (prompt + completion)
    return {
        "prompt_tokens": prompt,
        "completion_tokens": completion,
        "total_tokens": total
    }


def _extract_response_usage(response) -> dict:
    usage = getattr(response, "usage", None)
    prompt = _usage_get(usage, "input_tokens")
    completion = _usage_get(usage, "output_tokens")
    total = _usage_get(usage, "total_tokens") or (prompt + completion)
    return {
        "prompt_tokens": prompt,
        "completion_tokens": completion,
        "total_tokens": total
    }


def estimate_cost(
    snippet_usage: dict,
    embedding_tokens: int,
    snippet_input_price_per_1m: float,
    snippet_output_price_per_1m: float,
    embedding_price_per_1k: float
) -> dict:
    snippet_input_cost = (snippet_usage.get("prompt_tokens", 0) / 1_000_000) * snippet_input_price_per_1m
    snippet_output_cost = (snippet_usage.get("completion_tokens", 0) / 1_000_000) * snippet_output_price_per_1m
    embedding_cost = (embedding_tokens / 1_000) * embedding_price_per_1k
    total = snippet_input_cost + snippet_output_cost + embedding_cost
    return {
        "snippet_input_cost": snippet_input_cost,
        "snippet_output_cost": snippet_output_cost,
        "embedding_cost": embedding_cost,
        "total": total
    }


def get_snippet_prices(chat_deployment: str) -> tuple[float, float]:
    if chat_deployment == AZURE_OPENAI_CHAT_DEPLOYMENT_NANO:
        return PRICE_GPT5_NANO_INPUT_PER_1M, PRICE_GPT5_NANO_OUTPUT_PER_1M
    return PRICE_GPT5_MINI_INPUT_PER_1M, PRICE_GPT5_MINI_OUTPUT_PER_1M


def get_embedding_price(embedding_deployment: str) -> float:
    if embedding_deployment == AZURE_OPENAI_EMBEDDING_DEPLOYMENT_LARGE:
        return PRICE_EMBEDDING_LARGE_PER_1K
    return PRICE_EMBEDDING_SMALL_PER_1K


def _content_to_text(content) -> str:
    if isinstance(content, str):
        return content.strip()
    if isinstance(content, list):
        parts = []
        for part in content:
            if isinstance(part, dict):
                if part.get("type") in ("text", "output_text"):
                    parts.append(part.get("text", ""))
            else:
                if getattr(part, "type", None) in ("text", "output_text"):
                    parts.append(getattr(part, "text", ""))
        return "".join(parts).strip()
    return ""


def _response_to_text(response) -> str:
    text = getattr(response, "output_text", None)
    if isinstance(text, str) and text.strip():
        return text.strip()
    output = getattr(response, "output", None)
    if isinstance(output, list):
        parts = []
        for item in output:
            content = None
            if isinstance(item, dict):
                content = item.get("content")
                if item.get("type") in ("output_text", "text") and item.get("text"):
                    parts.append(item.get("text"))
            else:
                content = getattr(item, "content", None)
                item_type = getattr(item, "type", None)
                if item_type in ("output_text", "text"):
                    item_text = getattr(item, "text", None)
                    if item_text:
                        parts.append(item_text)
            if isinstance(content, list):
                for part in content:
                    if isinstance(part, dict):
                        if part.get("type") in ("output_text", "text"):
                            parts.append(part.get("text", ""))
                    else:
                        if getattr(part, "type", None) in ("output_text", "text"):
                            parts.append(getattr(part, "text", ""))
        return "".join(parts).strip()
    return ""


def generate_snippet_from_image(
    client: AzureOpenAI,
    image_base64: str,
    image_type: str,
    chat_deployment: str
) -> tuple[str, dict]:
    """
    ç”»åƒã‹ã‚‰snippetï¼ˆèª¬æ˜æ–‡ï¼‰ã‚’ç”Ÿæˆ
    é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆ
    """
    response = client.chat.completions.create(
        model=chat_deployment,
        messages=[
            {
                "role": "system",
                "content": "You are tasked with generating concise, accurate descriptions of images, figures, diagrams, or charts in documents."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "Please describe this image."
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/{image_type};base64,{image_base64}"
                        }
                    }
                ]
            }
        ],
        max_completion_tokens=300
    )
    usage = _extract_chat_usage(response)
    text = _content_to_text(response.choices[0].message.content)
    if text:
        return text, usage

    finish_reason = getattr(response.choices[0], "finish_reason", None)
    responses_error = None

    if hasattr(client, "responses"):
        try:
            resp = client.responses.create(
                model=chat_deployment,
                input=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "input_text", "text": "Please describe this image."},
                            {
                                "type": "input_image",
                                "image_url": f"data:image/{image_type};base64,{image_base64}"
                            }
                        ]
                    }
                ],
                max_output_tokens=1000
            )
            usage = _extract_response_usage(resp)
            text = _response_to_text(resp)
            if text:
                return text, usage
        except Exception as e:
            responses_error = f"{type(e).__name__}: {e}"

    refusal = getattr(response.choices[0].message, "refusal", None)
    raise RuntimeError(
        "ç”»åƒèª¬æ˜ãŒç©ºã§ã™ã€‚"
        f"finish_reason={finish_reason} "
        f"refusal={refusal} "
        f"responses_error={responses_error}"
    )


def generate_embedding(client: AzureOpenAI, text: str, embedding_deployment: str) -> tuple[list[float], int]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    é¸æŠã—ãŸåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    """
    response = client.embeddings.create(
        model=embedding_deployment,
        input=text
    )
    usage = getattr(response, "usage", None)
    tokens = _usage_get(usage, "total_tokens") or _usage_get(usage, "prompt_tokens")
    return response.data[0].embedding, tokens


def generate_sas_url(blob_url: str) -> str:
    """
    Blob URLã‹ã‚‰SASãƒˆãƒ¼ã‚¯ãƒ³ä»˜ãURLã‚’ç”Ÿæˆ
    blob_urlå½¢å¼: https://<account>.blob.core.windows.net/<container>/<blob_path>
    """
    if not AZURE_STORAGE_ACCOUNT_NAME or not AZURE_STORAGE_ACCOUNT_KEY:
        return blob_url  # SASç”Ÿæˆä¸å¯ã®å ´åˆã¯å…ƒã®URLã‚’è¿”ã™

    try:
        parsed = urlparse(blob_url)
        decoded_path = unquote(parsed.path)
        path_parts = decoded_path.lstrip("/").split("/", 1)

        if len(path_parts) < 2:
            return blob_url

        container_name = path_parts[0]
        blob_name = path_parts[1]

        sas_token = generate_blob_sas(
            account_name=AZURE_STORAGE_ACCOUNT_NAME,
            container_name=container_name,
            blob_name=blob_name,
            account_key=AZURE_STORAGE_ACCOUNT_KEY,
            permission=BlobSasPermissions(read=True),
            expiry=datetime.utcnow() + timedelta(hours=1)
        )

        return f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{sas_token}"
    except Exception as e:
        st.warning(f"SASãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return blob_url


def search_similar_images(
    search_client: SearchClient,
    embedding: list[float],
    top_k: int = 20
) -> list[dict]:
    """
    ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œ
    snippet_vectorãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½¿ç”¨
    """
    vector_query = VectorizedQuery(
        vector=embedding,
        k_nearest_neighbors=top_k,
        fields="snippet_vector"
    )

    results = search_client.search(
        search_text=None,
        vector_queries=[vector_query],
        select=["blob_url", "snippet"],
        top=top_k
    )

    search_results = []
    for result in results:
        search_results.append({
            "blob_url": result.get("blob_url", ""),
            "snippet": result.get("snippet", ""),
            "score": result.get("@search.score", 0)
        })

    return search_results


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    st.set_page_config(
        page_title="ç”»åƒæ¤œç´¢ãƒ‡ãƒ¢",
        page_icon="ğŸ”",
        layout="wide"
    )
    st.markdown(
        """
        <style>
          .result-image {
            width: 100%;
            object-fit: cover;
            display: block;
            border-radius: 8px;
          }
          .result-card {
            width: 100%;
            margin-bottom: 8px;
          }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("ğŸ” Azure AI Search ç”»åƒæ¤œç´¢ãƒ‡ãƒ¢")
    st.markdown("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€é¡ä¼¼ç”»åƒã‚’æ¤œç´¢ã—ã¾ã™ã€‚")

    patterns = get_patterns()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: æ¤œç´¢è¨­å®š
    with st.sidebar:
        st.header("æ¤œç´¢è¨­å®š")
        top_k = 5
        st.caption("æ¤œç´¢çµæœã¯ä¸Šä½5ä»¶ã‚’æ¯”è¼ƒè¡¨ç¤ºã—ã¾ã™")

        # st.markdown("---")
        # st.header("æ¯”è¼ƒãƒ‘ã‚¿ãƒ¼ãƒ³")
        # for pattern in patterns:
        #     st.caption(f"{pattern['label']} â†’ {pattern['index']}")

        st.markdown("---")
        st.header("æ–™é‡‘è¨ˆç®—")
        st.markdown(
            "Azure OpenAI ä¾¡æ ¼è¡¨: "
            "https://azure.microsoft.com/ja-jp/pricing/details/azure-openai/"
        )
        st.caption(
            f"GPT-5-mini å…¥åŠ›: {PRICE_GPT5_MINI_INPUT_PER_1M}å††/1M, å‡ºåŠ›: {PRICE_GPT5_MINI_OUTPUT_PER_1M}å††/1M"
        )
        st.caption(
            f"GPT-5-nano å…¥åŠ›: {PRICE_GPT5_NANO_INPUT_PER_1M}å††/1M, å‡ºåŠ›: {PRICE_GPT5_NANO_OUTPUT_PER_1M}å††/1M"
        )

        st.caption(
            f"text-embedding-3-large: {PRICE_EMBEDDING_LARGE_PER_1K}å††/1K"
        )
        st.caption(
            f"text-embedding-3-small: {PRICE_EMBEDDING_SMALL_PER_1K}å††/1K, "
        )


        st.markdown("### å‡¦ç†ãƒ•ãƒ­ãƒ¼")
        st.markdown("""
        1. ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        2. gpt-5-mini / gpt-5-nano ã§ç”»åƒèª¬æ˜ã‚’ç”Ÿæˆ
        3. text-embedding-3-small / text-embedding-3-large ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        4. 4ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§é¡ä¼¼æ¤œç´¢
        5. ä¸Šä½5ä»¶ã‚’æ¨ªä¸¦ã³æ¯”è¼ƒ
        """)

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    try:
        openai_client = init_openai_client()
    except Exception as e:
        st.error(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        st.info("`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: æ¥ç¶šè¨ºæ–­
    st.sidebar.markdown("---")
    st.sidebar.header("æ¥ç¶šè¨ºæ–­")
    with st.sidebar:
        with st.spinner("æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­..."):
            tests = [
                ("gpt-5-mini", AZURE_OPENAI_CHAT_DEPLOYMENT_MINI),
                ("gpt-5-nano", AZURE_OPENAI_CHAT_DEPLOYMENT_NANO)
            ]
            for label, deployment in tests:
                success, message = test_connection(openai_client, deployment)
                if success:
                    st.success(f"{label}: {message}")
                else:
                    st.error(f"{label}: {message}")
                    st.info(f"ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {AZURE_OPENAI_ENDPOINT}")

    # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "æ¤œç´¢ã™ã‚‹ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["jpg", "jpeg", "png"],
        help="JPGã¾ãŸã¯PNGç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )

    if uploaded_file is not None:
        # ç”»åƒã‚¿ã‚¤ãƒ—åˆ¤å®š
        image_type = uploaded_file.type.split("/")[-1] if uploaded_file.type else "png"
        if image_type.lower() == "jpg":
            image_type = "jpeg"

        # ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        col1, col2 = st.columns([1, 2])

        with col1:
            st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ")
            image = Image.open(uploaded_file)
            st.image(image, use_container_width=True)

        with col2:
            st.subheader("å‡¦ç†çŠ¶æ³")

            # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            uploaded_file.seek(0)
            image_bytes = uploaded_file.read()
            image_base64 = encode_image_to_base64(image_bytes)

            # snippetç”Ÿæˆ
            with st.spinner("ç”»åƒã‚’è§£æä¸­..."):
                snippet_by_chat = {}
                snippet_usage_by_chat = {}
                snippet_errors = {}
                snippet_time_by_chat = {}
                chat_models = [
                    ("gpt-5-mini", AZURE_OPENAI_CHAT_DEPLOYMENT_MINI),
                    ("gpt-5-nano", AZURE_OPENAI_CHAT_DEPLOYMENT_NANO)
                ]
                for label, chat_deployment in chat_models:
                    start_ts = time.monotonic()
                    try:
                        snippet, usage = generate_snippet_from_image(
                            openai_client, image_base64, image_type, chat_deployment
                        )
                        snippet_by_chat[chat_deployment] = snippet
                        snippet_usage_by_chat[chat_deployment] = usage
                    except Exception as e:
                        snippet_errors[chat_deployment] = (label, e)
                    finally:
                        snippet_time_by_chat[chat_deployment] = time.monotonic() - start_ts

                if snippet_by_chat:
                    st.success("ç”»åƒè§£æå®Œäº†")
                else:
                    for label, err in snippet_errors.values():
                        st.error(f"snippetç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({label}): {type(err).__name__}: {err}")
                    return

            # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼†æ¤œç´¢ï¼ˆ4ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
            pattern_results = {}
            pattern_meta = {}
            with st.spinner("ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨æ¤œç´¢ä¸­..."):
                for pattern in patterns:
                    pattern_id = pattern["id"]
                    chat_deployment = pattern["chat"]
                    embedding_deployment = pattern["embed"]
                    index_name = pattern["index"]

                    if chat_deployment not in snippet_by_chat:
                        pattern_meta[pattern_id] = {
                            "error": "snippetç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—",
                            "index": index_name
                        }
                        pattern_results[pattern_id] = []
                        continue

                    snippet = snippet_by_chat[chat_deployment]
                    try:
                        embedding, embedding_tokens = generate_embedding(
                            openai_client, snippet, embedding_deployment
                        )
                        search_client = init_search_client(index_name)
                        results = search_similar_images(search_client, embedding, top_k)

                        snippet_input_price, snippet_output_price = get_snippet_prices(chat_deployment)
                        embedding_price = get_embedding_price(embedding_deployment)
                        cost = estimate_cost(
                            snippet_usage_by_chat.get(chat_deployment, {}),
                            embedding_tokens,
                            snippet_input_price,
                            snippet_output_price,
                            embedding_price
                        )
                        pattern_meta[pattern_id] = {
                            "cost": cost,
                            "tokens": {
                                "prompt": snippet_usage_by_chat.get(chat_deployment, {}).get("prompt_tokens", 0),
                                "completion": snippet_usage_by_chat.get(chat_deployment, {}).get("completion_tokens", 0),
                                "embedding": embedding_tokens
                            },
                            "index": index_name
                        }
                        pattern_results[pattern_id] = results
                    except Exception as e:
                        pattern_meta[pattern_id] = {
                            "error": f"{type(e).__name__}: {e}",
                            "index": index_name
                        }
                        pattern_results[pattern_id] = []

        st.markdown("### ç”Ÿæˆã•ã‚ŒãŸsnippet")
        snippet_cols = st.columns(2, gap="large")
        for col, (label, deployment) in zip(snippet_cols, chat_models):
            with col:
                elapsed = snippet_time_by_chat.get(deployment)
                if elapsed is not None:
                    st.markdown(f"**{label}**ï¼ˆ{elapsed:.2f}sï¼‰")
                else:
                    st.markdown(f"**{label}**")
                if deployment in snippet_by_chat:
                    st.write(snippet_by_chat[deployment])
                else:
                    err = snippet_errors.get(deployment)
                    if err:
                        st.error(f"{type(err[1]).__name__}: {err[1]}")
                    else:
                        st.caption("æœªç”Ÿæˆ")

        # æ¤œç´¢çµæœæ¯”è¼ƒè¡¨ç¤º
        st.markdown("---")
        st.subheader("æ¤œç´¢çµæœæ¯”è¼ƒï¼ˆä¸Šä½5ä»¶ï¼‰")

        header_cols = st.columns(4, gap="small")
        for col, pattern in zip(header_cols, patterns):
            pattern_id = pattern["id"]
            meta = pattern_meta.get(pattern_id, {})
            with col:
                st.markdown(f"**{pattern['label']}**")
                st.caption(f"index: {pattern['index']}")
                if "error" in meta:
                    st.error(meta["error"])
                else:
                    cost = meta.get("cost", {})
                    st.caption(
                        f"ã‚³ã‚¹ãƒˆ: Â¥{cost.get('total', 0):.6f} "
                        f"(å…¥åŠ›: Â¥{cost.get('snippet_input_cost', 0):.6f}, "
                        f"å‡ºåŠ›: Â¥{cost.get('snippet_output_cost', 0):.6f}, "
                        f"Embedding: Â¥{cost.get('embedding_cost', 0):.6f})"
                    )
                    tokens = meta.get("tokens", {})
                    st.caption(
                        f"Tokens: prompt={tokens.get('prompt', 0)}, "
                        f"completion={tokens.get('completion', 0)}, "
                        f"embedding={tokens.get('embedding', 0)}"
                    )

        for rank in range(top_k):
            row_cols = st.columns(4, gap="small")
            for col, pattern in zip(row_cols, patterns):
                pattern_id = pattern["id"]
                results = pattern_results.get(pattern_id, [])
                with col:
                    if rank < len(results):
                        result = results[rank]
                        st.markdown(f"**#{rank + 1}** (ã‚¹ã‚³ã‚¢: {result['score']:.4f})")

                        sas_url = generate_sas_url(result["blob_url"])
                        try:
                            resp = httpx.get(sas_url, timeout=10.0, verify=certifi.where())
                            content_type = resp.headers.get("content-type", "")
                            if resp.status_code == 200 and content_type.startswith("image/"):
                                render_result_image(resp.content, content_type)
                            else:
                                st.caption("ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
                        except Exception:
                            st.caption("ç”»åƒã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")

                        with st.expander("snippet"):
                            st.write(result["snippet"])
                    else:
                        st.caption(f"#{rank + 1} è©²å½“ãªã—")


if __name__ == "__main__":
    main()
